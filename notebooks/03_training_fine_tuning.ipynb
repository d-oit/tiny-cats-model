{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Training & Fine-Tuning TinyDiT\n",
    "\n",
    "Learn how to train or fine-tune the TinyDiT model on your own cat breed dataset.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Understand training configuration\n",
    "- Prepare custom datasets\n",
    "- Run local and Modal GPU training\n",
    "- Export and upload models to HuggingFace\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**For Local Training:**\n",
    "- Python 3.10+\n",
    "- PyTorch with CUDA (GPU recommended)\n",
    "- 8GB+ VRAM for full training\n",
    "\n",
    "**For Modal GPU Training:**\n",
    "- Modal account (free tier available)\n",
    "- Modal CLI installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision modal huggingface_hub pillow numpy matplotlib -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Preparation\n",
    "\n",
    "### Step 1.1: Organize Your Dataset\n",
    "\n",
    "The training script expects the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create example dataset structure\n",
    "dataset_dir = Path(\"my_custom_cats\")\n",
    "breeds = [\"abyssinian\", \"bengal\", \"persian\", \"other\"]\n",
    "\n",
    "for breed in breeds:\n",
    "    (dataset_dir / breed).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset structure created at: {dataset_dir.absolute()}\")\n",
    "print(\"\\nExpected structure:\")\n",
    "print(f\"\"\"\n",
    "{dataset_dir}/\n",
    "├── abyssinian/\n",
    "│   ├── image1.jpg\n",
    "│   ├── image2.jpg\n",
    "│   └── ...\n",
    "├── bengal/\n",
    "│   └── ...\n",
    "├── persian/\n",
    "│   └── ...\n",
    "└── other/\n",
    "    └── (non-cat images or unknown breeds)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Dataset Requirements\n",
    "\n",
    "| Requirement | Minimum | Recommended |\n",
    "|-------------|---------|-------------|\n",
    "| Images per breed | 50 | 200+ |\n",
    "| Image size | 128x128 | 512x512+ |\n",
    "| Formats | JPG, PNG | JPG |\n",
    "| Total dataset | 500 images | 2000+ images |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_quality(dataset_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze dataset quality and provide recommendations.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    from collections import Counter\n",
    "    \n",
    "    dataset = Path(dataset_path)\n",
    "    breeds = [d for d in dataset.iterdir() if d.is_dir()]\n",
    "    \n",
    "    stats = {\n",
    "        \"num_breeds\": len(breeds),\n",
    "        \"breed_counts\": {},\n",
    "        \"total_images\": 0,\n",
    "        \"warnings\": []\n",
    "    }\n",
    "    \n",
    "    for breed_dir in breeds:\n",
    "        images = list(breed_dir.glob(\"*.jpg\")) + list(breed_dir.glob(\"*.png\"))\n",
    "        count = len(images)\n",
    "        stats[\"breed_counts\"][breed_dir.name] = count\n",
    "        stats[\"total_images\"] += count\n",
    "        \n",
    "        if count < 50:\n",
    "            stats[\"warnings\"].append(\n",
    "                f\"⚠️  {breed_dir.name}: Only {count} images (need 50+)\"\n",
    "            )\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Dataset quality checker defined!\")\n",
    "print(\"Usage: check_dataset_quality('my_custom_cats')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training Configuration\n",
    "\n",
    "### Step 2.1: Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    # Dataset\n",
    "    \"data_dir\": \"my_custom_cats\",\n",
    "    \n",
    "    # Training\n",
    "    \"steps\": 50000,  # Fine-tuning (100k for full training)\n",
    "    \"batch_size\": 32,  # Reduce if OOM\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"gradient_accumulation_steps\": 2,  # Effective batch = 64\n",
    "    \"warmup_steps\": 5000,\n",
    "    \n",
    "    # Model\n",
    "    \"image_size\": 128,\n",
    "    \"augmentations\": \"full\",  # full, basic, or none\n",
    "    \n",
    "    # Output\n",
    "    \"checkpoint_interval\": 10000,\n",
    "    \"output_dir\": \"checkpoints\",\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in training_config.items():\n",
    "    print(f\"{key:30s}: {value}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Estimate training time\n",
    "effective_batch = training_config[\"batch_size\"] * training_config[\"gradient_accumulation_steps\"]\n",
    "estimated_gpu_hours = training_config[\"steps\"] * effective_batch / 50000\n",
    "print(f\"\\nEffective batch size: {effective_batch}\")\n",
    "print(f\"Estimated GPU hours: {estimated_gpu_hours:.1f} (on H100/A10G)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Local Training (GPU/CPU)\n",
    "\n",
    "### Step 3.1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠️  No GPU detected - training will be slow on CPU\")\n",
    "    print(\"   Consider using Modal GPU training (Part 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Run Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Build training command\n",
    "cmd = [\n",
    "    sys.executable, \"src/train_dit.py\",\n",
    "    training_config[\"data_dir\"],\n",
    "    \"--steps\", str(training_config[\"steps\"]),\n",
    "    \"--batch-size\", str(training_config[\"batch_size\"]),\n",
    "    \"--lr\", str(training_config[\"learning_rate\"]),\n",
    "    \"--gradient-accumulation-steps\", str(training_config[\"gradient_accumulation_steps\"]),\n",
    "    \"--warmup-steps\", str(training_config[\"warmup_steps\"]),\n",
    "    \"--augmentation-level\", training_config[\"augmentations\"],\n",
    "]\n",
    "\n",
    "print(\"Training command:\")\n",
    "print(\" \".join(cmd))\n",
    "print(\"\\n⏳ Starting training... (this will take a while)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run training\n",
    "# Note: Commented out to avoid running in notebook\n",
    "# subprocess.run(cmd)\n",
    "\n",
    "print(\"\\n✅ Training would start with the above command\")\n",
    "print(\"To run training, uncomment the subprocess.run(cmd) line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Modal GPU Training (Recommended)\n",
    "\n",
    "### Step 4.1: Setup Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Modal if not already installed\n",
    "!pip install modal -q\n",
    "\n",
    "# Authenticate (run once)\n",
    "# !modal token set\n",
    "\n",
    "print(\"Modal setup complete!\")\n",
    "print(\"Note: Run 'modal token set' to authenticate if prompted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Define Modal Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "\n",
    "# Define Modal app\n",
    "app = modal.App(\"tiny-cats-training\")\n",
    "\n",
    "# Define GPU image\n",
    "image = modal.Image.debian_slim().pip_install(\n",
    "    \"torch\", \"torchvision\", \"modal\", \"huggingface_hub\", \"pillow\", \"numpy\"\n",
    ")\n",
    "\n",
    "# Define training function\n",
    "@app.function(\n",
    "    gpu=\"T4\",  # or \"A10G\", \"H100\"\n",
    "    timeout=7200,  # 2 hours\n",
    "    volumes={\"/data\": modal.Volume.from_name(\"cats-data\", create_if_missing=True)}\n",
    ")\n",
    "def train_on_modal():\n",
    "    import subprocess\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \"src/train_dit.py\",\n",
    "        \"/data/cats\",  # Dataset in volume\n",
    "        \"--steps\", \"100000\",\n",
    "        \"--batch-size\", \"256\",\n",
    "        \"--gradient-accumulation-steps\", \"2\",\n",
    "        \"--lr\", \"1e-4\",\n",
    "        \"--augmentation-level\", \"full\",\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(cmd)\n",
    "\n",
    "print(\"Modal training function defined!\")\n",
    "print(\"Usage: train_on_modal.remote()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Run Modal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training (commented out to avoid actual execution)\n",
    "# with app.run():\n",
    "#     train_on_modal.remote()\n",
    "\n",
    "print(\"Modal training ready!\")\n",
    "print(\"\\nTo run training:\")\n",
    "print(\"1. Uncomment the code above\")\n",
    "print(\"2. Ensure dataset is in Modal volume\")\n",
    "print(\"3. Run the cell\")\n",
    "print(\"\\nOr use CLI:\")\n",
    "print(\"  modal run src/train_dit.py data/cats --steps 100000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Export Model\n",
    "\n",
    "### Step 5.1: Load Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Find latest checkpoint\n",
    "checkpoint_dir = Path(\"checkpoints\")\n",
    "checkpoints = list(checkpoint_dir.glob(\"dit_step_*.pt\"))\n",
    "\n",
    "if checkpoints:\n",
    "    latest_checkpoint = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Latest checkpoint: {latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"No checkpoints found - run training first\")\n",
    "    latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2: Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_checkpoint:\n",
    "    from src.export_dit_onnx import export_generator_onnx\n",
    "    \n",
    "    print(\"Exporting model to ONNX...\")\n",
    "    export_generator_onnx(\n",
    "        checkpoint_path=str(latest_checkpoint),\n",
    "        output_path=\"custom_generator.onnx\",\n",
    "        opset=17,\n",
    "    )\n",
    "    \n",
    "    import os\n",
    "    size_mb = os.path.getsize(\"custom_generator.onnx\") / 1e6\n",
    "    print(f\"✅ Exported to custom_generator.onnx ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(\"Skipping export - no checkpoint available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.3: Quantization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(\"custom_generator.onnx\").exists():\n",
    "    from src.optimize_onnx import quantize_model_dynamic\n",
    "    \n",
    "    print(\"Quantizing model...\")\n",
    "    quantize_model_dynamic(\n",
    "        input_path=\"custom_generator.onnx\",\n",
    "        output_path=\"custom_generator_quantized.onnx\",\n",
    "    )\n",
    "    \n",
    "    import os\n",
    "    original_size = os.path.getsize(\"custom_generator.onnx\") / 1e6\n",
    "    quantized_size = os.path.getsize(\"custom_generator_quantized.onnx\") / 1e6\n",
    "    reduction = (1 - quantized_size / original_size) * 100\n",
    "    \n",
    "    print(f\"✅ Quantized: {original_size:.2f}MB → {quantized_size:.2f}MB ({reduction:.1f}% reduction)\")\n",
    "else:\n",
    "    print(\"Skipping quantization - export model first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Upload to HuggingFace\n",
    "\n",
    "### Step 6.1: Setup Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, create_repo, login\n",
    "import os\n",
    "\n",
    "# Get HuggingFace username\n",
    "username = input(\"Enter your HuggingFace username: \").strip()\n",
    "repo_name = input(\"Enter repository name (e.g., my-cats-model): \").strip()\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "print(f\"\\nRepository ID: {repo_id}\")\n",
    "\n",
    "# Create repository\n",
    "print(\"\\nCreating repository...\")\n",
    "try:\n",
    "    create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n",
    "    print(f\"✅ Repository created: https://huggingface.co/{repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Repository may already exist: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2: Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "\n",
    "# Files to upload\n",
    "files_to_upload = [\n",
    "    (\"custom_generator.onnx\", \"generator/model.onnx\"),\n",
    "    (\"custom_generator_quantized.onnx\", \"generator/model_quantized.onnx\"),\n",
    "]\n",
    "\n",
    "print(f\"\\nUploading files to {repo_id}...\")\n",
    "\n",
    "for local_path, repo_path in files_to_upload:\n",
    "    if Path(local_path).exists():\n",
    "        print(f\"  Uploading {local_path} → {repo_path}\")\n",
    "        try:\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=local_path,\n",
    "                path_in_repo=repo_path,\n",
    "                repo_id=repo_id,\n",
    "            )\n",
    "            print(f\"    ✅ Success\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Error: {e}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  Skipping {local_path} (not found)\")\n",
    "\n",
    "print(f\"\\n✅ Upload complete!\")\n",
    "print(f\"View your model: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3: Create Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = f\"\"\"---\n",
    "license: mit\n",
    "tags:\n",
    "- cat\n",
    "- diffusion\n",
    "- generative\n",
    "- pytorch\n",
    "---\n",
    "\n",
    "# {repo_name}\n",
    "\n",
    "A custom-trained TinyDiT model for generating cat images.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Architecture:** TinyDiT (Diffusion Transformer)\n",
    "- **Training Steps:** {training_config['steps']:,}\n",
    "- **Dataset:** Custom cat breeds\n",
    "- **License:** MIT\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"{repo_id}\",\n",
    "    filename=\"generator/model.onnx\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Training Configuration\n",
    "\n",
    "```python\n",
    "{training_config}\n",
    "```\n",
    "\n",
    "## Generated Samples\n",
    "\n",
    "![Samples](samples.png)\n",
    "\n",
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@misc{{{repo_name.replace('-', '_')}},\n",
    "  title = {{{repo_name}}},\n",
    "  author = {{Your Name}},\n",
    "  year = {{2026}},\n",
    "  url = {{https://huggingface.co/{repo_id}}}\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Save model card\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(model_card)\n",
    "\n",
    "print(\"Model card created: README.md\")\n",
    "\n",
    "# Upload model card\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"README.md\",\n",
    "    path_in_repo=\"README.md\",\n",
    "    repo_id=repo_id,\n",
    ")\n",
    "print(f\"✅ Model card uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ You've learned how to:\n",
    "- Prepare a custom dataset\n",
    "- Configure training parameters\n",
    "- Run local and Modal GPU training\n",
    "- Export models to ONNX\n",
    "- Upload to HuggingFace\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Share your model with the community\n",
    "- Read [ADR-036](../plans/ADR-036-high-accuracy-training-configuration.md) for advanced training\n",
    "- Try [Notebook 01](01_quickstart_classification.ipynb) for classification\n",
    "- Try [Notebook 02](02_conditional_generation.ipynb) for generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Issue: Out of Memory\n",
    "**Solution:** Reduce batch_size or use gradient accumulation\n",
    "\n",
    "### Issue: Slow Training\n",
    "**Solution:** Use Modal GPU or increase num_workers\n",
    "\n",
    "### Issue: Poor Sample Quality\n",
    "**Solution:** Increase training steps or check data quality\n",
    "\n",
    "### Issue: Upload Fails\n",
    "**Solution:** Check HF_TOKEN permissions and repository access"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
