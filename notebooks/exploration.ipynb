{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny-Cats-Model â€” Data Exploration\n",
    "\n",
    "This notebook guides you through:\n",
    "1. Exploring the dataset (class distribution, sample images)\n",
    "2. Checking image statistics (mean/std per channel)\n",
    "3. Visualising data augmentation transforms\n",
    "4. Inspecting model architecture and parameter counts\n",
    "5. Training a quick sanity-check run\n",
    "6. Plotting training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure project root is on path\n",
    "sys.path.insert(0, str(Path('.').resolve()))\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Dataset Overview"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import cats_dataloader, get_transforms\n",
    "\n",
    "DATA_DIR = 'data/cats'  # adjust if needed\n",
    "\n",
    "# Count images per class\n",
    "data_path = Path(DATA_DIR)\n",
    "class_counts = {}\n",
    "if data_path.exists():\n",
    "    for cls in sorted(data_path.iterdir()):\n",
    "        if cls.is_dir():\n",
    "            images = list(cls.glob('*.jpg')) + list(cls.glob('*.jpeg')) + list(cls.glob('*.png'))\n",
    "            class_counts[cls.name] = len(images)\n",
    "\n",
    "    print('Classes found:', list(class_counts.keys()))\n",
    "    for name, count in class_counts.items():\n",
    "        print(f'  {name}: {count} images')\n",
    "else:\n",
    "    print(f'Data directory {DATA_DIR} not found. Run data/download.sh first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "if class_counts:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.bar(class_counts.keys(), class_counts.values(), color='steelblue', edgecolor='white')\n",
    "    ax.set_title('Class Distribution')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Number of images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Sample Images"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(data_dir, n_per_class=4):\n",
    "    path = Path(data_dir)\n",
    "    classes = sorted([d for d in path.iterdir() if d.is_dir()])\n",
    "    fig, axes = plt.subplots(len(classes), n_per_class, figsize=(n_per_class * 3, len(classes) * 3))\n",
    "    if len(classes) == 1:\n",
    "        axes = [axes]\n",
    "    for row, cls in enumerate(classes):\n",
    "        images = list(cls.glob('*.jpg')) + list(cls.glob('*.png'))\n",
    "        samples = random.sample(images, min(n_per_class, len(images)))\n",
    "        for col, img_path in enumerate(samples):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            axes[row][col].imshow(img)\n",
    "            axes[row][col].axis('off')\n",
    "            if col == 0:\n",
    "                axes[row][col].set_title(cls.name, fontsize=12, fontweight='bold')\n",
    "    plt.suptitle('Sample Images per Class', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if data_path.exists():\n",
    "    show_samples(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Augmentation Visualisation"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = get_transforms('train')\n",
    "val_tf   = get_transforms('val')\n",
    "\n",
    "if data_path.exists():\n",
    "    sample_img_path = next(iter(data_path.rglob('*.jpg')))\n",
    "    orig = Image.open(sample_img_path).convert('RGB')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "    axes[0].imshow(orig.resize((224, 224)))\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    for i in range(1, 6):\n",
    "        aug = train_tf(orig).permute(1, 2, 0).numpy()\n",
    "        aug = np.clip(aug, 0, 1)\n",
    "        axes[i].imshow(aug)\n",
    "        axes[i].set_title(f'Augmented {i}')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle('Train Augmentations')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Model Inspection"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import cats_model, count_parameters, SUPPORTED_BACKBONES\n",
    "\n",
    "print('Supported backbones:', SUPPORTED_BACKBONES)\n",
    "\n",
    "for backbone in SUPPORTED_BACKBONES:\n",
    "    m = cats_model(num_classes=2, backbone=backbone, pretrained=False)\n",
    "    params = count_parameters(m)\n",
    "    print(f'  {backbone}: {params:,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Quick Training Sanity Check"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model import cats_model\n",
    "from train import get_optimizer, train_one_epoch, validate\n",
    "\n",
    "# Synthetic data sanity check\n",
    "x = torch.randn(16, 3, 224, 224)\n",
    "y = torch.randint(0, 2, (16,))\n",
    "ds = TensorDataset(x, y)\n",
    "loader = DataLoader(ds, batch_size=4)\n",
    "\n",
    "model = cats_model(num_classes=2, backbone='resnet18', pretrained=False)\n",
    "opt   = get_optimizer(model, 'adamw', lr=1e-3)\n",
    "\n",
    "train_losses, val_accs = [], []\n",
    "for epoch in range(5):\n",
    "    loss = train_one_epoch(model, loader, opt, device='cpu')\n",
    "    metrics = validate(model, loader, device='cpu')\n",
    "    train_losses.append(loss)\n",
    "    val_accs.append(metrics['accuracy'])\n",
    "    print(f'Epoch {epoch+1}/5 | loss={loss:.4f} | acc={metrics[\"accuracy\"]:.3f}')\n",
    "\n",
    "print('Sanity check passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Training Curves"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, len(train_losses)+1), train_losses, marker='o', color='steelblue')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2.plot(range(1, len(val_accs)+1), val_accs, marker='o', color='darkorange')\n",
    "ax2.set_title('Validation Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
